{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charge Carrier Trapping Experiment\n",
    "\n",
    "CCT = Charge Carrier Trapping - This is a test of comparing the Zhou et al 2017 results with a data driven analysis using multinest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab  import *;ion()\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from time   import time\n",
    "\n",
    "from exoparams import PlanetParams\n",
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h38_visit1 = read_csv('HATP38_all/1.125-1.642_LC_negative_first.dat', delimiter='\\t', skiprows=[1])\n",
    "h38_visit2 = read_csv('HATP38_all/1.125-1.642_LC_negative_second.dat', delimiter='\\t', skiprows=[1])\n",
    "w67_visit1 = read_csv('wasp67_all/1.125-1.642_LC_negative.dat', delimiter='\\t', skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(h38_visit1['Flux'][:15] / median(h38_visit1['Flux']), 'o')\n",
    "plot(h38_visit2['Flux'][:15] / median(h38_visit1['Flux']), 'o')\n",
    "plot(w67_visit1['Flux'][:15] / median(w67_visit1['Flux']), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hat38_par  = PlanetParams('HAT-P-38 b')\n",
    "wasp67_par = PlanetParams('WASP-67 b')\n",
    "# # hat38_par.t0\n",
    "# hat38_par.t0 = u.Quantity(2455863.11957, unit=hat38_par.t0.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hat38_per = hat38_par.per.value\n",
    "hat38_t0  = 2455863.11957 - 2400000.5#hat38_par.t0.value - 2400000.5\n",
    "\n",
    "wasp67_per = wasp67_par.per.value\n",
    "wasp67_t0  = wasp67_par.t0.value - 2400000.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_orbit  = 45/60/24\n",
    "\n",
    "w67_v1_orbit_gaps  = where(diff(w67_visit1['Time [d]']) > half_orbit)[0]\n",
    "h38_v1_orbit_gaps  = where(diff(h38_visit1['Time [d]']) > half_orbit)[0]\n",
    "h38_v2_orbit_gaps  = where(diff(h38_visit2['Time [d]']) > half_orbit)[0]\n",
    "\n",
    "print(w67_visit1['Flux'][w67_v1_orbit_gaps[0]] / median(w67_visit1['Flux']))\n",
    "print(h38_visit1['Flux'][h38_v1_orbit_gaps[0]] / median(h38_visit1['Flux']))\n",
    "print(h38_visit2['Flux'][h38_v2_orbit_gaps[0]] / median(h38_visit2['Flux']))\n",
    "\n",
    "w67_v1_fixed_inds = concatenate([arange(w67_v1_orbit_gaps[0]), \\\n",
    "                                 arange(w67_v1_orbit_gaps[0]+1, w67_visit1['Flux'].size)])\n",
    "h38_v1_fixed_inds = concatenate([arange(h38_v1_orbit_gaps[0]), \\\n",
    "                                 arange(h38_v1_orbit_gaps[0]+1, h38_visit1['Flux'].size)])\n",
    "h38_v2_fixed_inds = concatenate([arange(h38_v2_orbit_gaps[0]), \\\n",
    "                                 arange(h38_v2_orbit_gaps[0]+1, h38_visit2['Flux'].size)])\n",
    "\n",
    "w67_v1_fixed_dict = {}\n",
    "h38_v1_fixed_dict = {}\n",
    "h38_v2_fixed_dict = {}\n",
    "for key in w67_visit1.keys():\n",
    "    w67_v1_fixed_dict[key] = w67_visit1[key][w67_v1_fixed_inds]\n",
    "\n",
    "for key in h38_visit1.keys():\n",
    "    h38_v1_fixed_dict[key] = h38_visit1[key][h38_v1_fixed_inds]\n",
    "\n",
    "for key in h38_visit2.keys():\n",
    "    h38_v2_fixed_dict[key] = h38_visit2[key][h38_v2_fixed_inds]\n",
    "\n",
    "w67_visit1_store = w67_visit1.copy()\n",
    "h38_visit1_store = h38_visit1.copy()\n",
    "h38_visit2_store = h38_visit2.copy()\n",
    "\n",
    "w67_visit1       = DataFrame(w67_v1_fixed_dict)\n",
    "h38_visit1       = DataFrame(h38_v1_fixed_dict)\n",
    "h38_visit2       = DataFrame(h38_v2_fixed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w67_phase1  = ((w67_visit1['Time [d]'].values - wasp67_t0) % wasp67_per) / wasp67_per\n",
    "h38_phase1  = ((h38_visit1['Time [d]'].values - hat38_t0 ) % hat38_per ) / hat38_per\n",
    "h38_phase2  = ((h38_visit2['Time [d]'].values - hat38_t0 ) % hat38_per ) / hat38_per\n",
    "\n",
    "w67_phase1[w67_phase1 > 0.5] -= 1\n",
    "h38_phase1[h38_phase1 > 0.5] -= 1\n",
    "h38_phase2[h38_phase2 > 0.5] -= 1\n",
    "\n",
    "w67_visit1['Phase'] = w67_phase1\n",
    "h38_visit1['Phase'] = h38_phase1\n",
    "h38_visit2['Phase'] = h38_phase2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if the data makes sense as is**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "errorbar(h38_phase1, h38_visit1['Flux'] / median(h38_visit1['Flux']), h38_visit1['Sigma'] / median(h38_visit1['Flux']), fmt='o', label='HAT-38 Visit 1')\n",
    "errorbar(h38_phase2, h38_visit2['Flux'] / median(h38_visit2['Flux']), h38_visit2['Sigma'] / median(h38_visit2['Flux']), fmt='o', label='HAT-38 Visit 2')\n",
    "errorbar(w67_phase1, w67_visit1['Flux'] / median(w67_visit1['Flux']), w67_visit1['Sigma'] / median(w67_visit1['Flux']), fmt='o', label='Wasp-67 Visit 1')\n",
    "\n",
    "legend(loc=0)\n",
    "# ylim(.98,1.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_hst_by_orbit(visit_df, skipOrbit=[]):\n",
    "    \n",
    "    if not isinstance(skipOrbit, (list, tuple)):\n",
    "        skipOrbit = [skipOrbit]\n",
    "    \n",
    "    half_orbit  = 45/60/24\n",
    "    orbit_gaps  = hstack([[0],where(diff(visit_df['Time [d]']) > half_orbit)[0]])\n",
    "    nOrbits     = orbit_gaps.size\n",
    "    \n",
    "    print(nOrbits, orbit_gaps)\n",
    "    \n",
    "    orbitNumber        = []\n",
    "    phased_DeltaPhase  = []\n",
    "    phased_DeltaTime   = []\n",
    "    phased_Flux        = []\n",
    "    phased_Sigma       = []\n",
    "\n",
    "    for korbit in range(nOrbits-1):\n",
    "        if korbit not in skipOrbit:\n",
    "            print('Activating\\tOrbit', korbit)\n",
    "            orbit_start = orbit_gaps[korbit]+1\n",
    "            orbit_stop  = orbit_gaps[korbit+1]+1\n",
    "            \n",
    "            orbit_phase = visit_df['Phase'][orbit_start:orbit_stop].values\n",
    "            orbit_times = visit_df['Time [d]'][orbit_start:orbit_stop].values\n",
    "            orbit_flux  = visit_df['Flux'][orbit_start:orbit_stop].values\n",
    "            orbit_sigma = visit_df['Sigma'][orbit_start:orbit_stop].values\n",
    "            \n",
    "            orbitNumber.append(korbit*ones(orbit_phase.size))\n",
    "            phased_DeltaPhase.append(orbit_phase - orbit_phase[0])\n",
    "            phased_DeltaTime.append( orbit_times - orbit_times[0])\n",
    "            phased_Flux.append(      orbit_flux / orbit_flux[-1] )\n",
    "            phased_Sigma.append(     orbit_sigma/ orbit_flux[-1] )\n",
    "        else:\n",
    "            print('Skipping\\torbit', korbit)\n",
    "    \n",
    "    if korbit+1 not in skipOrbit:\n",
    "        print('Activating\\tOrbit', korbit+1)\n",
    "        orbit_start = orbit_gaps[korbit+1]+1\n",
    "\n",
    "        orbit_phase = visit_df['Phase'][orbit_start:].values\n",
    "        orbit_times = visit_df['Time [d]'][orbit_start:].values\n",
    "        orbit_flux  = visit_df['Flux'][orbit_start:].values\n",
    "        orbit_sigma = visit_df['Sigma'][orbit_start:].values\n",
    "        \n",
    "        orbitNumber.append(korbit*ones(orbit_phase.size) + 1)\n",
    "        phased_DeltaPhase.append(orbit_phase - orbit_phase[0])\n",
    "        phased_DeltaTime.append( orbit_times - orbit_times[0])\n",
    "        phased_Flux.append(      orbit_flux / orbit_flux[-1] )\n",
    "        phased_Sigma.append(     orbit_sigma/ orbit_flux[-1] )        \n",
    "    else: \n",
    "        print('Skipping\\tOrbit', korbit+1)\n",
    "    \n",
    "    # sort_by_phase      = phased_DeltaPhase.argsort()\n",
    "    phase_split_dict  = {'DeltaPhase' : phased_DeltaPhase, \\\n",
    "                         'DeltaTimes' : phased_DeltaTime , \\\n",
    "                         'Flux'       : phased_Flux      , \\\n",
    "                         'Sigma'      : phased_Sigma     , \\\n",
    "                         'orbitNumber': orbitNumber      }\n",
    "    \n",
    "    return DataFrame(phase_split_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_hst_by_orbit(visit_df, skipOrbit=[], phaseOrbits=False):\n",
    "    \n",
    "    if not isinstance(skipOrbit, (list, tuple)):\n",
    "        skipOrbit = [skipOrbit]\n",
    "    \n",
    "    half_orbit  = 45/60/24\n",
    "    orbit_gaps  = hstack([[0],where(diff(visit_df['Time [d]']) > half_orbit)[0]])\n",
    "    nOrbits     = orbit_gaps.size\n",
    "    \n",
    "    print(nOrbits, orbit_gaps)\n",
    "    \n",
    "    orbitNumber        = []\n",
    "    phased_DeltaPhase  = []\n",
    "    phased_DeltaTime   = []\n",
    "    phased_Flux        = []\n",
    "    phased_Sigma       = []\n",
    "\n",
    "    for korbit in range(nOrbits-1):\n",
    "        if korbit not in skipOrbit:\n",
    "            print('Activating\\tOrbit', korbit)\n",
    "            orbit_start = orbit_gaps[korbit]+1\n",
    "            orbit_stop  = orbit_gaps[korbit+1]+1\n",
    "\n",
    "            orbit_phase = visit_df['Phase'][orbit_start:orbit_stop].values\n",
    "            orbit_times = visit_df['Time [d]'][orbit_start:orbit_stop].values\n",
    "            orbit_flux  = visit_df['Flux'][orbit_start:orbit_stop].values\n",
    "            orbit_sigma = visit_df['Sigma'][orbit_start:orbit_stop].values\n",
    "            \n",
    "            orbitNumber        = concatenate([orbitNumber      , korbit*ones(orbit_phase.size)])\n",
    "            phased_DeltaPhase  = concatenate([phased_DeltaPhase, orbit_phase - orbit_phase[0]])\n",
    "            phased_DeltaTime   = concatenate([phased_DeltaTime , orbit_times - orbit_times[0]])\n",
    "            phased_Flux        = concatenate([phased_Flux      , orbit_flux / orbit_flux[-1] ])\n",
    "            phased_Sigma       = concatenate([phased_Sigma     , orbit_sigma/ orbit_flux[-1]])\n",
    "        else:\n",
    "            print('Skipping\\tOrbit', korbit)\n",
    "    \n",
    "    if korbit+1 not in skipOrbit:\n",
    "        print('Activating\\tOrbit', korbit+1)\n",
    "        orbit_start = orbit_gaps[korbit+1]+1\n",
    "\n",
    "        orbit_phase = visit_df['Phase'][orbit_start:].values\n",
    "        orbit_times = visit_df['Time [d]'][orbit_start:].values\n",
    "        orbit_flux  = visit_df['Flux'][orbit_start:].values\n",
    "        orbit_sigma = visit_df['Sigma'][orbit_start:].values\n",
    "        \n",
    "        orbitNumber        = concatenate([orbitNumber      , korbit*ones(orbit_phase.size) +1])\n",
    "        phased_DeltaPhase  = concatenate([phased_DeltaPhase, orbit_phase - orbit_phase[0]])\n",
    "        phased_DeltaTime   = concatenate([phased_DeltaTime , orbit_times - orbit_times[0]])\n",
    "        phased_Flux        = concatenate([phased_Flux      , orbit_flux / orbit_flux[-1] ])\n",
    "        phased_Sigma       = concatenate([phased_Sigma     , orbit_sigma/ orbit_flux[-1]])\n",
    "    else: \n",
    "        print('Skipping\\tOrbit', korbit+1)\n",
    "    \n",
    "    if phaseOrbits:\n",
    "        sort_by_phase = phased_DeltaPhase.argsort()\n",
    "    else:\n",
    "        sort_by_phase = np.arange(phased_DeltaPhase.size)\n",
    "    \n",
    "    phased_dict        = {'DeltaPhase' : phased_DeltaPhase[sort_by_phase], \\\n",
    "                          'DeltaTimes' : phased_DeltaTime[sort_by_phase] , \\\n",
    "                          'Flux'       : phased_Flux[sort_by_phase]      , \\\n",
    "                          'Sigma'      : phased_Sigma[sort_by_phase]     , \\\n",
    "                          'OrbitNumber': orbitNumber[sort_by_phase]      }\n",
    "    \n",
    "    return DataFrame(phased_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w67_v1_skipOrbit  = [0,2]\n",
    "h38_v1_skipOrbit  = [0,2,3]\n",
    "h38_v2_skipOrbit  = [0,2,3]\n",
    "\n",
    "print('\\nWASP-67 Visit 1')\n",
    "w67_v1_orbitSplit = split_hst_by_orbit(w67_visit1, skipOrbit=w67_v1_skipOrbit)\n",
    "print('\\nHAT-P-38 Visit1')\n",
    "h38_v1_orbitSplit = split_hst_by_orbit(h38_visit1, skipOrbit=h38_v1_skipOrbit)\n",
    "print('\\nHAT-P-38 Visit2')\n",
    "h38_v2_orbitSplit = split_hst_by_orbit(h38_visit2, skipOrbit=h38_v2_skipOrbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w67_v1_skipOrbit  = [0,2]\n",
    "h38_v1_skipOrbit  = [0,2,3]\n",
    "h38_v2_skipOrbit  = [0,2,3]\n",
    "\n",
    "print('\\nW67 V1')\n",
    "w67_v1_orbitPhased = sort_hst_by_orbit(w67_visit1, skipOrbit=w67_v1_skipOrbit, phaseOrbits=False)\n",
    "print('\\nH38 V1')\n",
    "h38_v1_orbitPhased = sort_hst_by_orbit(h38_visit1, skipOrbit=h38_v1_skipOrbit, phaseOrbits=False)\n",
    "print('\\nH38 V2')\n",
    "h38_v2_orbitPhased = sort_hst_by_orbit(h38_visit2, skipOrbit=h38_v2_skipOrbit, phaseOrbits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(10,10))\n",
    "errorbar(h38_v1_orbitPhased['DeltaPhase'], h38_v1_orbitPhased['Flux'] , h38_v1_orbitPhased['Sigma'], fmt='o')\n",
    "\n",
    "fig = figure(figsize=(10,10))\n",
    "errorbar(np.arange(h38_v1_orbitPhased['DeltaPhase'].size), h38_v1_orbitPhased['Flux'] , h38_v1_orbitPhased['Sigma'], fmt='o')\n",
    "# errorbar(h38_v2_orbitPhased['DeltaPhase'], h38_v2_orbitPhased['Flux'] , h38_v2_orbitPhased['Sigma'], fmt='o')\n",
    "# errorbar(w67_v1_orbitPhased['DeltaPhase'], w67_v1_orbitPhased['Flux'] , w67_v1_orbitPhased['Sigma'], fmt='o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in h38_v1_orbitPhased['OrbitNumber'].unique():\n",
    "    orbitNNow = h38_v1_orbitPhased['OrbitNumber'] == k\n",
    "    errorbar(h38_v1_orbitPhased['DeltaPhase'][orbitNNow]    , \\\n",
    "             h38_v1_orbitPhased['Flux'][orbitNNow]          , \\\n",
    "             h38_v1_orbitPhased['Sigma'][orbitNNow], fmt='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(10,10))\n",
    "# errorbar(w67_v1_orbitPhased['DeltaPhase'], w67_v1_orbitPhased['Flux'] , w67_v1_orbitPhased['Sigma'], fmt='o')\n",
    "# errorbar(h38_v1_orbitPhased['DeltaPhase'], h38_v1_orbitPhased['Flux'] , h38_v1_orbitPhased['Sigma'], fmt='o')\n",
    "# errorbar(h38_v2_orbitPhased['DeltaPhase'], h38_v2_orbitPhased['Flux'] , h38_v2_orbitPhased['Sigma'], fmt='o')\n",
    "\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax3 = fig.add_subplot(313)\n",
    "\n",
    "for k in range(len(h38_v1_orbitSplit['DeltaPhase'])):\n",
    "    ax1.errorbar(h38_v1_orbitSplit['DeltaPhase'][k], h38_v1_orbitSplit['Flux'][k], h38_v1_orbitSplit['Sigma'][k], fmt='o')\n",
    "\n",
    "for k in range(len(h38_v2_orbitSplit['DeltaPhase'])):\n",
    "    ax2.errorbar(h38_v2_orbitSplit['DeltaPhase'][k], h38_v2_orbitSplit['Flux'][k], h38_v2_orbitSplit['Sigma'][k], fmt='o')\n",
    "\n",
    "for k in range(len(w67_v1_orbitSplit['DeltaPhase'])):\n",
    "    ax3.errorbar(w67_v1_orbitSplit['DeltaPhase'][k], w67_v1_orbitSplit['Flux'][k], w67_v1_orbitSplit['Sigma'][k], fmt='o')\n",
    "\n",
    "ax1.set_title('h38_v1_orbitSplit');\n",
    "ax2.set_title('h38_v2_orbitSplit');\n",
    "ax3.set_title('w67_v1_orbitSplit');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_exponential_model(params, orbit_phase):\n",
    "    alpha = params[0]\n",
    "    beta  = params[1]\n",
    "    gamma = params[2]\n",
    "    \n",
    "    return alpha - beta*exp(-gamma*phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def double_exponential_model(params, orbit_phase):\n",
    "    alpha   = params[0]\n",
    "    beta    = params[1]\n",
    "    gamma   = params[2]\n",
    "    delta   = params[3]\n",
    "    epsilon = params[4]\n",
    "    \n",
    "    return alpha - beta*exp(-gamma*phase) - delta*exp(-epsilon*phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zhou_model(params):\n",
    "    # Zhou et al. 2017\n",
    "    # The exponential ramp timescale is detector dependennt, and therfore uniform across all observations\n",
    "    # But the difference from orbit to orbit is predicted to be related \n",
    "    #   ONLY to the inital number of charge traps populated at the start of the each ramp\n",
    "    \n",
    "    # BIG ASSUMPTION\n",
    "    \n",
    "    flux    = ydata.copy() # I assume that what Zhou means by `flux` is either the WLC or avg WLC value\n",
    "    # flux    = ydata.copy() / 128 # I assume that what Zhou means by `flux` is either the WLC or avg WLC value\n",
    "    \n",
    "    E0fast  = params[0] # Orbit 0; Start with per frame; may want per pixel\n",
    "    E0slow  = params[1] # Orbit 0; Start with per frame; may want per pixel\n",
    "    \n",
    "    # Separate out the delta-E0 components per orbit\n",
    "    # Keep dE0fast[0] and dE0slow[0] == 0.0 because they correspond to E0fast and E0slow (initial)\n",
    "    dE0fast     = np.zeros(nOrbits)\n",
    "    dE0slow     = np.zeros(nOrbits)\n",
    "    for k in range(1, nOrbits):\n",
    "        print(k,2*k, 2*k+1,len(params))\n",
    "        dE0fast[k] = params[2*k]\n",
    "        dE0slow[k] = params[2*k+1]\n",
    "    \n",
    "    # From Table 3 of Zhou et al. 2017\n",
    "    ETotFast  = 270.6\n",
    "    etaFast   = 0.006863\n",
    "    tauFast   = 224.8\n",
    "    \n",
    "    ETotSlow  = 1320.0\n",
    "    etaSlow   = 0.01311\n",
    "    tauSlow   = 2.45e4\n",
    "    \n",
    "    coeffFast0= (etaFast * flux / ETotFast + tauFast**-1)\n",
    "    coeffSlow0= (etaSlow * flux / ETotSlow + tauSlow**-1)\n",
    "    \n",
    "    coeffFast1= etaFast*flux / coeffFast0\n",
    "    coeffSlow1= etaSlow*flux / coeffSlow0\n",
    "    \n",
    "    Efast     = zeros(orbit_phase.shape)\n",
    "    Eslow     = zeros(orbit_phase.shape)\n",
    "    for k in range(nOrbits):\n",
    "        orbitNow         = where(orbitNumber == k)[0]\n",
    "        Efast[orbitNow]  = coeffFast1 + (E0fast + dE0fast[k] - coeffFast1)*exp(-coeffFast0 * tphase[orbitNow])\n",
    "        Eslow[orbitNow]  = coeffSlow1 + (E0slow + dE0slow[k] - coeffSlow1)*exp(-coeffSlow0 * tphase[orbitNow])\n",
    "    \n",
    "    dEFastDtP = etaFast * flux * (ETotFast - Efast) / ETotFast\n",
    "    dEFastDtN = -Efast / tauFast\n",
    "    \n",
    "    dESlowDtP = etaSlow * flux * (ETotSlow - Eslow) / ETotSlow\n",
    "    dESlowDtN = -Eslow / tauSlow\n",
    "    \n",
    "    lambda phase: 1 - dEFastDtP - dESlowDtP - dEFastDtP - dESlowDtP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMultiNest Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, unicode_literals, print_function\n",
    "import pymultinest\n",
    "import math\n",
    "import os\n",
    "import threading, subprocess\n",
    "from sys import platform\n",
    "\n",
    "if not os.path.exists(\"chains\"): os.mkdir(\"chains\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *;ion()\n",
    "\n",
    "# from pymultinest.solve import Solver,solve\n",
    "from numpy import pi, sin, cos, linspace\n",
    "\n",
    "def single_exponential_model(cube):\n",
    "    alpha = cube[0]\n",
    "    beta  = cube[1]\n",
    "    gamma = cube[2]\n",
    "    \n",
    "    return lambda xdata: alpha - beta*exp(-gamma*xdata)\n",
    "\n",
    "def double_exponential_model(cube):\n",
    "    alpha   = cube[0]\n",
    "    beta    = cube[1]\n",
    "    gamma   = cube[2]\n",
    "    delta   = cube[3]\n",
    "    epsilon = cube[4]\n",
    "    \n",
    "    return lambda xdata: alpha - beta*exp(-gamma*xdata) - delta*exp(-epsilon*xdata)\n",
    "\n",
    "def straight_line(cube):\n",
    "    offset = cube[0]\n",
    "    slope  = cube[1]\n",
    "    return lambda abscissa: offset + slope * abscissa\n",
    "\n",
    "def sine_wave(cube):\n",
    "    amp    = cube[0]\n",
    "    period = cube[1]\n",
    "    return lambda abscissa: amp*sin(2*pi / period * abscissa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "param0_test= 1#0.05\n",
    "param1_test= .1#5*pi\n",
    "param2_test= 10.0\n",
    "yunc_test  = 0.01\n",
    "nPts_test  = int(50)\n",
    "nThPts_test= int(1e3)\n",
    "\n",
    "xmin_test  = -0.0#*pi\n",
    "xmax_test  =  1.0#*pi\n",
    "dx_test    = 0.01*(xmax_test - xmin_test)\n",
    "\n",
    "model_test = single_exponential_model\n",
    "# model_test = sine_wave\n",
    "# model_test = straight_line\n",
    "\n",
    "yuncs_test = np.random.normal(yunc_test, 1e-2 * yunc_test, nPts_test)\n",
    "thdata_test= np.linspace(xmin_test-dx_test, xmax_test+dx_test, nThPts_test)\n",
    "\n",
    "xdata_test = np.random.uniform(xmin_test, xmax_test, nPts_test)\n",
    "xdata_test = sort(xdata_test)\n",
    "\n",
    "ydata_test = model_test([param0_test,param1_test,param2_test])(xdata_test)\n",
    "\n",
    "yerr_test  = np.random.normal(0, yuncs_test, nPts_test)\n",
    "zdata_test = ydata_test + yerr_test\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plot(thdata_test, model_test([param0_test,param1_test,param2_test])(thdata_test))\n",
    "errorbar(xdata_test, zdata_test, yunc_test*ones(zdata_test.size), fmt='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Exponential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nThPts    = int(1e3)\n",
    "model_SEM = single_exponential_model\n",
    "\n",
    "xdata = h38_v1_orbitPhased['DeltaPhase']\n",
    "ydata = h38_v1_orbitPhased['Flux']\n",
    "yuncs = h38_v1_orbitPhased['Sigma']\n",
    "\n",
    "xmin, xmax = xdata.min(), xdata.max()\n",
    "dx         = (xmax - xmin)/100\n",
    "thdata_SEM = np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "param0_SEM_init= 1.0  # by defintion\n",
    "param1_SEM_init= (ydata.max() - ydata.min())#/100\n",
    "param2_SEM_init= round(5/(xdata.max() - xdata.min()))\n",
    "\n",
    "print(param0_SEM_init, param1_SEM_init, param2_SEM_init)\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plot(thdata_SEM, model_SEM([param0_SEM_init,param1_SEM_init,param2_SEM_init])(thdata_SEM))\n",
    "errorbar(xdata, ydata, yuncs, fmt='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "# model = sine_wave\n",
    "# parameters = [\"amp\", \"period\"]\n",
    "\n",
    "# model = straight_line\n",
    "# parameters = [\"offset\", \"slope\"]\n",
    "\n",
    "model_SEM       = single_exponential_model\n",
    "parameters_SEM  = ['max', 'amp1', 'scale1']\n",
    "\n",
    "def myprior_SEM(cube, ndim, nparams):\n",
    "    cube0_width = 1e-3\n",
    "    cube[0] = cube[0] * cube0_width  + (1 - 0.5*cube0_width)# - 10# U(0,2)\n",
    "    cube[1] = cube[1] # - 10# U(0,1) -- default\n",
    "    cube[2] = cube[2] * 1e4   - 5e3# - 1000 # U(0,2000)\n",
    "\n",
    "def myloglike_SEM(cube, ndim, nparams):\n",
    "    chi = 1.\n",
    "    # print \"cube\", [cube[i] for i in range(ndim)], cube\n",
    "    # for i in range(ndim):\n",
    "    #     chi *= -0.5 * ((cube[i] - 0.2) / 0.1)**2#math.cos(cube[i] / 2.) * math.sin(cube[i] / 2.)\n",
    "    # print \"returning\", math.pow(2. + chi, 5)\n",
    "    modelNow = model_SEM(cube)(xdata)\n",
    "    return -0.5*((modelNow - ydata)**2. / yuncs**2.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number of dimensions our problem has\n",
    "# parameters = [\"x\", \"y\"]\n",
    "n_params_SEM = len(parameters_SEM)\n",
    "\n",
    "planetName           = 'HAT38'\n",
    "visitName            = 'visit1'\n",
    "modelName            = 'single_exponential_model'\n",
    "outputfiles_basename = 'chains/' + planetName + '-' + visitName + '-' + modelName + '-'\n",
    "\n",
    "start = time()\n",
    "\n",
    "plt.figure(figsize=(5*n_params_SEM, 5*n_params_SEM))\n",
    "# we want to see some output while it is running\n",
    "progress = pymultinest.ProgressPlotter(n_params = n_params_SEM, outputfiles_basename=outputfiles_basename); progress.start()\n",
    "# threading.Timer(2, show, [\"chains/2-phys_live.points.pdf\"]).start() # delayed opening\n",
    "# run MultiNest\n",
    "pymultinest.run(myloglike_SEM, myprior_SEM, n_params_SEM, \\\n",
    "                importance_nested_sampling = False, resume = False, verbose = True, \\\n",
    "                sampling_efficiency = 'model', n_live_points = 1000, outputfiles_basename=outputfiles_basename);\n",
    "\n",
    "# ok, done. Stop our progress watcher\n",
    "progress.stop();\n",
    "print('SEM took', time() - start, 'seconds')\n",
    "# lets analyse the results\n",
    "a_SEM = pymultinest.Analyzer(n_params = n_params_SEM, outputfiles_basename=outputfiles_basename);\n",
    "s_SEM = a_SEM.get_stats();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a_SEM.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters_SEM, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a_SEM.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s_SEM, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"Global Evidence:\\t%.15e +- %.15e\" % ( s_SEM['nested sampling global log-evidence'], \\\n",
    "                                             s_SEM['nested sampling global log-evidence error'] ))\n",
    "print(\"Global Evidence:\\t%.3f +- %.3f\" % ( s_SEM['nested sampling global log-evidence'], \\\n",
    "                                             s_SEM['nested sampling global log-evidence error'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "\n",
    "# Here we will plot all the marginals and whatnot, just to show off\n",
    "# You may configure the format of the output here, or in matplotlibrc\n",
    "# All pymultinest does is filling in the data of the plot.\n",
    "\n",
    "# Copy and edit this file, and play with it.\n",
    "\n",
    "p_SEM = pymultinest.PlotMarginalModes(a_SEM)\n",
    "plt.figure(figsize=(5*n_params_SEM, 5*n_params_SEM))\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for i in range(n_params_SEM):\n",
    "    plt.subplot(n_params_SEM, n_params_SEM, n_params_SEM * i + i + 1)\n",
    "    p_SEM.plot_marginal(i, with_ellipses = False, with_points = False, grid_points=50)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters_SEM[i])\n",
    "    \n",
    "    for j in range(i):\n",
    "        plt.subplot(n_params_SEM, n_params_SEM, n_params_SEM * j + i + 1)\n",
    "        #plt.subplots_adjust(left=0, bottom=0, right=0, top=0, wspace=0, hspace=0)\n",
    "        p_SEM.plot_conditional(i, j, with_ellipses = False, with_points = False, grid_points=30)\n",
    "        plt.xlabel(parameters_SEM[i])\n",
    "        plt.ylabel(parameters_SEM[j])\n",
    "\n",
    "# plt.savefig(\"chains/marginals_multinest.pdf\") #, bbox_inches='tight')\n",
    "# show(\"chains/marginals_multinest.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "# plt.subplot2grid((5*n_params, 5*n_params), loc=(0,0))\n",
    "for i in range(n_params_SEM):\n",
    "    # print(5*n_params, 1, i+1)\n",
    "    plt.subplot(5*n_params_SEM, 1, i+1)\n",
    "    p_SEM.plot_modes_marginal(i, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters_SEM[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # outfile = '%s-mode-marginal-cumulative-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p_SEM.plot_modes_marginal(i, cumulative = True, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.xlabel(parameters_SEM[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_SEM.analyser.get_best_fit()['parameters'], [param0_SEM_init, param1_SEM_init, param2_SEM_init]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "plot(thdata_SEM, model_SEM([param0_SEM_init,param1_SEM_init, param2_SEM_init])(thdata_SEM), label='Initial Model')\n",
    "errorbar(xdata, ydata, yuncs, fmt='o', label='Data')\n",
    "plot(thdata_SEM, model_SEM(p_SEM.analyser.get_best_fit()['parameters'])(thdata_SEM), label='PMN Model')\n",
    "legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_SEM.analyser.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unrestricted Double Exponential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nThPts= int(1e3)\n",
    "model_UDEM = double_exponential_model\n",
    "\n",
    "xdata = h38_v1_orbitPhased['DeltaPhase']\n",
    "ydata = h38_v1_orbitPhased['Flux']\n",
    "yuncs = h38_v1_orbitPhased['Sigma']\n",
    "\n",
    "xmin, xmax = xdata.min(), xdata.max()\n",
    "dx         = (xmax - xmin)/100\n",
    "thdata_UDEM = np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "param0_UDEM_init  = 1.0  # by defintion\n",
    "param1_UDEM_init  = 0.5*(ydata.max() - ydata.min())#/100\n",
    "param2_UDEM_init  = round(5/(xdata.max() - xdata.min()))\n",
    "param3_UDEM_init  = 0.5*(ydata.max() - ydata.min())#/100\n",
    "param4_UDEM_init  = round(5/(xdata.max() - xdata.min()))\n",
    "\n",
    "print(param0_UDEM_init, param1_UDEM_init, param2_UDEM_init, param3_UDEM_init, param4_UDEM_init)\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plot(thdata_UDEM, model_UDEM([param0_UDEM_init,param1_UDEM_init,param2_UDEM_init, param3_UDEM_init, param4_UDEM_init])(thdata_UDEM))\n",
    "errorbar(xdata, ydata, yuncs, fmt='o')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def show(filepath): \n",
    "    \"\"\" open the output (pdf) file for the user \"\"\"\n",
    "    if os.name == 'mac' or platform == 'darwin': subprocess.call(('open', filepath))\n",
    "    elif os.name == 'nt' or platform == 'win32': os.startfile(filepath)\n",
    "    elif platform.startswith('linux') : subprocess.call(('xdg-open', filepath))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "\n",
    "def myprior0(cube, ndim, nparams):\n",
    "    #print \"cube before\", [cube[i] for i in range(ndim)]\n",
    "    for i in range(ndim):\n",
    "        cube[i] = cube[i] * 10 * math.pi\n",
    "    #print \"python cube after\", [cube[i] for i in range(ndim)]\n",
    "\n",
    "def myloglike0(cube, ndim, nparams):\n",
    "    chi = 1.\n",
    "    #print \"cube\", [cube[i] for i in range(ndim)], cube\n",
    "    for i in range(ndim):\n",
    "        chi *= math.cos(cube[i] / 2.) * math.sin(cube[i] / 2.)\n",
    "    #print \"returning\", math.pow(2. + chi, 5)\n",
    "    return math.pow(2. + chi, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "# model = sine_wave\n",
    "# parameters = [\"amp\", \"period\"]\n",
    "\n",
    "# model = straight_line\n",
    "# parameters = [\"offset\", \"slope\"]\n",
    "\n",
    "model_UDEM      = double_exponential_model\n",
    "parameters_UDEM = ['max', 'amp1', 'scale1', 'amp2', 'scale2']\n",
    "\n",
    "# def myprior_RDEM(cube, ndim, nparams):\n",
    "#     cube[0] = cube[0] * 1e-3  + (1 - 1e-3/2)# - 10# U(0,2)\n",
    "#     cube[1] = -cube[1] * 5e-3 + 5e-4 # - 10# U(0,1) -- default\n",
    "#     cube[2] = cube[2] * 1e4   - 5e3# - 1000 # U(0,2000)\n",
    "#     cube[3] = cube[3] * 5e-3  + 5e-4# - 10# U(0,1) -- default\n",
    "#     cube[4] = cube[4] * 1e4   - 5e3# - 1000 # U(0,2000)\n",
    "\n",
    "def myprior_UDEM(cube, ndim, nparams):\n",
    "    cube[0] = cube[0] * 1e-3  + (1 - 1e-3/2)# - 10# U(0,2)\n",
    "    cube[1] = cube[1] * 2     - 1 # - 10# U(0,1) -- default\n",
    "    cube[2] = cube[2] * 1e4   - 5e3# - 1000 # U(0,2000)\n",
    "    cube[3] = cube[3] * 2     - 1# - 10# U(0,1) -- default\n",
    "    cube[4] = cube[4] * 1e4   - 5e3# - 1000 # U(0,2000)\n",
    "\n",
    "def myloglike_UDEM(cube, ndim, nparams):\n",
    "    chi = 1.\n",
    "    # print \"cube\", [cube[i] for i in range(ndim)], cube\n",
    "    # for i in range(ndim):\n",
    "    #     chi *= -0.5 * ((cube[i] - 0.2) / 0.1)**2#math.cos(cube[i] / 2.) * math.sin(cube[i] / 2.)\n",
    "    # print \"returning\", math.pow(2. + chi, 5)\n",
    "    modelNow = model_UDEM(cube)()\n",
    "    return -0.5*((modelNow - ydata)**2. / yuncs**2.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "# number of dimensions our problem has\n",
    "# parameters = [\"x\", \"y\"]\n",
    "n_params_UDEM = len(parameters_UDEM)\n",
    "\n",
    "savedir              = 'chains'\n",
    "planetName           = 'HAT38'\n",
    "visitName            = 'visit1'\n",
    "modelName            = 'unrestricted_double_exponential_model'\n",
    "outputfiles_basename = savedir + '/' + planetName + '-' + visitName + '-' + modelName + '-'\n",
    "\n",
    "plt.figure(figsize=(5*n_params_UDEM, 5*n_params_UDEM))\n",
    "# we want to see some output while it is running\n",
    "progress = pymultinest.ProgressPlotter(n_params = n_params_UDEM, outputfiles_basename=outputfiles_basename); progress.start()\n",
    "# threading.Timer(2, show, [\"chains/2-phys_live.points.pdf\"]).start() # delayed opening\n",
    "# run MultiNest\n",
    "pymultinest.run(myloglike_UDEM, myprior_UDEM, n_params_UDEM, importance_nested_sampling = False, resume = False, verbose = True, \\\n",
    "            sampling_efficiency = 'model', n_live_points = 1000, outputfiles_basename=outputfiles_basename)\n",
    "\n",
    "# ok, done. Stop our progress watcher\n",
    "progress.stop()\n",
    "\n",
    "# lets analyse the results\n",
    "a_UDEM = pymultinest.Analyzer(n_params = n_params_UDEM, outputfiles_basename=outputfiles_basename)\n",
    "s_UDEM = a_UDEM.get_stats()\n",
    "print('UDEM took', time() - start, 'seconds')\n",
    "\n",
    "# fig = plt.gcf()\n",
    "# axs = fig.get_axes()\n",
    "\n",
    "# for ax in axs:\n",
    "#     ax.set_ylim()\n",
    "#     # ax.set_xscale(\"log\", nonposx='clip')\n",
    "#     # ax.set_yscale(\"log\", nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a_UDEM.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters_UDEM, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a_UDEM.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s_UDEM, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"Global Evidence:\\t%.15e +- %.15e\" % ( s_UDEM['nested sampling global log-evidence'], \\\n",
    "                                               s_UDEM['nested sampling global log-evidence error'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "\n",
    "# Here we will plot all the marginals and whatnot, just to show off\n",
    "# You may configure the format of the output here, or in matplotlibrc\n",
    "# All pymultinest does is filling in the data of the plot.\n",
    "\n",
    "# Copy and edit this file, and play with it.\n",
    "\n",
    "p_UDEM = pymultinest.PlotMarginalModes(a_UDEM)\n",
    "plt.figure(figsize=(5*n_params_UDEM, 5*n_params_UDEM))\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for i in range(n_params_UDEM):\n",
    "    plt.subplot(n_params_UDEM, n_params_UDEM, n_params_UDEM * i + i + 1)\n",
    "    p_UDEM.plot_marginal(i, with_ellipses = False, with_points = False, grid_points=50)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters_UDEM[i])\n",
    "    \n",
    "    for j in range(i):\n",
    "        plt.subplot(n_params_UDEM, n_params_UDEM, n_params_UDEM * j + i + 1)\n",
    "        #plt.subplots_adjust(left=0, bottom=0, right=0, top=0, wspace=0, hspace=0)\n",
    "        p_UDEM.plot_conditional(i, j, with_ellipses = False, with_points = False, grid_points=30)\n",
    "        plt.xlabel(parameters_UDEM[i])\n",
    "        plt.ylabel(parameters_UDEM[j])\n",
    "\n",
    "# plt.savefig(\"chains/marginals_multinest.pdf\") #, bbox_inches='tight')\n",
    "# show(\"chains/marginals_multinest.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "# plt.subplot2grid((5*n_params, 5*n_params), loc=(0,0))\n",
    "for i in range(n_params_UDEM):\n",
    "    # print(5*n_params, 1, i+1)\n",
    "    plt.subplot(5*n_params_UDEM, 1, i+1)\n",
    "    p_UDEM.plot_modes_marginal(i, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters_UDEM[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # outfile = '%s-mode-marginal-cumulative-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p_UDEM.plot_modes_marginal(i, cumulative = True, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.xlabel(parameters_UDEM[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_UDEM.analyser.get_best_fit()['parameters'], [param0_UDEM_init, param1_UDEM_init, param2_UDEM_init, param3_UDEM_init, param4_UDEM_init]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "plot(thdata_UDEM, model_UDEM([param0_UDEM_init,param1_UDEM_init, param2_UDEM_init, param3_UDEM_init, param4_UDEM_init])(thdata_UDEM), label='Initial Model')\n",
    "errorbar(xdata, ydata, yuncs, fmt='o', label='Data')\n",
    "plot(thdata_UDEM, model_UDEM(p_UDEM.analyser.get_best_fit()['parameters'])(thdata_UDEM), label='PMN UDEM Model')\n",
    "legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_UDEM.analyser.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Double Exponential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nThPts= int(1e3)\n",
    "model_RDEM = double_exponential_model\n",
    "\n",
    "xdata = h38_v1_orbitPhased['DeltaPhase']\n",
    "ydata = h38_v1_orbitPhased['Flux']\n",
    "yuncs = h38_v1_orbitPhased['Sigma']\n",
    "\n",
    "xmin, xmax = xdata.min(), xdata.max()\n",
    "dx         = (xmax - xmin)/100\n",
    "thdata_RDEM = np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "param0_RDEM_init  = 1.0  # by defintion\n",
    "param1_RDEM_init  = 0.5*(ydata.max() - ydata.min())#/100\n",
    "param2_RDEM_init  = round(5/(xdata.max() - xdata.min()))\n",
    "param3_RDEM_init  = 0.5*(ydata.max() - ydata.min())#/100\n",
    "param4_RDEM_init  = round(5/(xdata.max() - xdata.min()))\n",
    "\n",
    "print(param0_RDEM_init, param1_RDEM_init, param2_RDEM_init, param3_RDEM_init, param4_RDEM_init)\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plot(thdata_RDEM, model_RDEM([param0_RDEM_init,param1_RDEM_init,param2_RDEM_init, param3_RDEM_init, param4_RDEM_init])(thdata_RDEM))\n",
    "errorbar(xdata, ydata, yuncs, fmt='o')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def show(filepath): \n",
    "    \"\"\" open the output (pdf) file for the user \"\"\"\n",
    "    if os.name == 'mac' or platform == 'darwin': subprocess.call(('open', filepath))\n",
    "    elif os.name == 'nt' or platform == 'win32': os.startfile(filepath)\n",
    "    elif platform.startswith('linux') : subprocess.call(('xdg-open', filepath))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "\n",
    "def myprior0(cube, ndim, nparams):\n",
    "    #print \"cube before\", [cube[i] for i in range(ndim)]\n",
    "    for i in range(ndim):\n",
    "        cube[i] = cube[i] * 10 * math.pi\n",
    "    #print \"python cube after\", [cube[i] for i in range(ndim)]\n",
    "\n",
    "def myloglike0(cube, ndim, nparams):\n",
    "    chi = 1.\n",
    "    #print \"cube\", [cube[i] for i in range(ndim)], cube\n",
    "    for i in range(ndim):\n",
    "        chi *= math.cos(cube[i] / 2.) * math.sin(cube[i] / 2.)\n",
    "    #print \"returning\", math.pow(2. + chi, 5)\n",
    "    return math.pow(2. + chi, 5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rm -rf chains/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "# model = sine_wave\n",
    "# parameters = [\"amp\", \"period\"]\n",
    "\n",
    "# model = straight_line\n",
    "# parameters = [\"offset\", \"slope\"]\n",
    "\n",
    "model_RDEM      = double_exponential_model\n",
    "parameters_RDEM = ['max', 'amp1', 'scale1', 'amp2', 'scale2']\n",
    "\n",
    "def myprior_RDEM(cube, ndim, nparams):\n",
    "    cube[0] = cube[0] * 1e-3  + (1 - 1e-3/2)# - 10# U(0,2)\n",
    "    cube[1] = -cube[1] * 5e-3 + 5e-4 # - 10# U(0,1) -- default\n",
    "    cube[2] = cube[2] * 1e4   - 5e3# - 1000 # U(0,2000)\n",
    "    cube[3] = cube[3] * 5e-3  + 5e-4# - 10# U(0,1) -- default\n",
    "    cube[4] = cube[4] * 1e4   - 5e3# - 1000 # U(0,2000)\n",
    "\n",
    "def myloglike_RDEM(cube, ndim, nparams):\n",
    "    chi = 1.\n",
    "    # print \"cube\", [cube[i] for i in range(ndim)], cube\n",
    "    # for i in range(ndim):\n",
    "    #     chi *= -0.5 * ((cube[i] - 0.2) / 0.1)**2#math.cos(cube[i] / 2.) * math.sin(cube[i] / 2.)\n",
    "    # print \"returning\", math.pow(2. + chi, 5)\n",
    "    modelNow = model_RDEM(cube)(xdata)\n",
    "    return -0.5*((modelNow - ydata)**2. / yuncs**2.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "# number of dimensions our problem has\n",
    "# parameters = [\"x\", \"y\"]\n",
    "n_params_RDEM = len(parameters_RDEM)\n",
    "\n",
    "savedir              = 'chains'\n",
    "planetName           = 'HAT38'\n",
    "visitName            = 'visit1'\n",
    "modelName            = 'restricted_double_exponential_model'\n",
    "outputfiles_basename = savedir + '/' + planetName + '-' + visitName + '-' + modelName + '-'\n",
    "\n",
    "plt.figure(figsize=(5*n_params_RDEM, 5*n_params_RDEM))\n",
    "# we want to see some output while it is running\n",
    "progress = pymultinest.ProgressPlotter(n_params = n_params_RDEM, outputfiles_basename=outputfiles_basename); progress.start()\n",
    "# threading.Timer(2, show, [\"chains/2-phys_live.points.pdf\"]).start() # delayed opening\n",
    "# run MultiNest\n",
    "pymultinest.run(myloglike_RDEM, myprior_RDEM, n_params_RDEM, importance_nested_sampling = False, resume = False, verbose = True, \\\n",
    "            sampling_efficiency = 'model', n_live_points = 1000, outputfiles_basename=outputfiles_basename)\n",
    "\n",
    "# ok, done. Stop our progress watcher\n",
    "progress.stop()\n",
    "\n",
    "# lets analyse the results\n",
    "a_RDEM = pymultinest.Analyzer(n_params = n_params_RDEM, outputfiles_basename=outputfiles_basename)\n",
    "s_RDEM = a_RDEM.get_stats()\n",
    "print('RDEM took', time() - start, 'seconds')\n",
    "\n",
    "# fig = plt.gcf()\n",
    "# axs = fig.get_axes()\n",
    "\n",
    "# for ax in axs:\n",
    "#     ax.set_ylim()\n",
    "#     # ax.set_xscale(\"log\", nonposx='clip')\n",
    "#     # ax.set_yscale(\"log\", nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a_RDEM.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters_RDEM, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a_RDEM.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s_RDEM, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"Global Evidence:\\t%.15e +- %.15e\" % ( s_RDEM['nested sampling global log-evidence'], \\\n",
    "                                               s_RDEM['nested sampling global log-evidence error'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "\n",
    "# Here we will plot all the marginals and whatnot, just to show off\n",
    "# You may configure the format of the output here, or in matplotlibrc\n",
    "# All pymultinest does is filling in the data of the plot.\n",
    "\n",
    "# Copy and edit this file, and play with it.\n",
    "\n",
    "p_RDEM = pymultinest.PlotMarginalModes(a_RDEM)\n",
    "plt.figure(figsize=(5*n_params_RDEM, 5*n_params_RDEM))\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for i in range(n_params_RDEM):\n",
    "    plt.subplot(n_params_RDEM, n_params_RDEM, n_params_RDEM * i + i + 1)\n",
    "    p_RDEM.plot_marginal(i, with_ellipses = False, with_points = False, grid_points=50)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters_RDEM[i])\n",
    "    \n",
    "    for j in range(i):\n",
    "        plt.subplot(n_params_RDEM, n_params_RDEM, n_params_RDEM * j + i + 1)\n",
    "        #plt.subplots_adjust(left=0, bottom=0, right=0, top=0, wspace=0, hspace=0)\n",
    "        p_RDEM.plot_conditional(i, j, with_ellipses = False, with_points = False, grid_points=30)\n",
    "        plt.xlabel(parameters_RDEM[i])\n",
    "        plt.ylabel(parameters_RDEM[j])\n",
    "\n",
    "# plt.savefig(\"chains/marginals_multinest.pdf\") #, bbox_inches='tight')\n",
    "# show(\"chains/marginals_multinest.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "# plt.subplot2grid((5*n_params, 5*n_params), loc=(0,0))\n",
    "for i in range(n_params_RDEM):\n",
    "    # print(5*n_params, 1, i+1)\n",
    "    plt.subplot(5*n_params_RDEM, 1, i+1)\n",
    "    p_RDEM.plot_modes_marginal(i, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters_RDEM[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # outfile = '%s-mode-marginal-cumulative-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p_RDEM.plot_modes_marginal(i, cumulative = True, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.xlabel(parameters_RDEM[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_RDEM.analyser.get_best_fit()['parameters'], [param0_RDEM_init, param1_RDEM_init, param2_RDEM_init, param3_RDEM_init, param4_RDEM_init]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "plot(thdata_RDEM, model_RDEM([param0_RDEM_init,param1_RDEM_init, param2_RDEM_init, param3_RDEM_init, param4_RDEM_init])(thdata_RDEM), label='Initial Model')\n",
    "errorbar(xdata, ydata, yuncs, fmt='o', label='Data')\n",
    "plot(thdata_RDEM, model_RDEM(p_RDEM.analyser.get_best_fit()['parameters'])(thdata_RDEM), label='PMN Model')\n",
    "legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_RDEM.analyser.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Unrestricted Double, Restricted Double, and Single Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a_SEM.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters_SEM, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a_SEM.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s_SEM, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"SEM Global Evidence:\\t\\t%.3f +- %.3f\" % ( s_SEM['nested sampling global log-evidence'], \\\n",
    "                                                   s_SEM['nested sampling global log-evidence error'] ))\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a_UDEM.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters_UDEM, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a_UDEM.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s_UDEM, f, indent=2)\n",
    "\n",
    "# print()\n",
    "# print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"UDEM Global Evidence:\\t\\t%.3f +- %.3f\" % ( s_UDEM['nested sampling global log-evidence'], \\\n",
    "                                                   s_UDEM['nested sampling global log-evidence error'] ))\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a_RDEM.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters_RDEM, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a_RDEM.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s_RDEM, f, indent=2)\n",
    "\n",
    "# print()\n",
    "# print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"RDEM Global Evidence:\\t\\t%.3f +- %.3f\" % ( s_RDEM['nested sampling global log-evidence'], \\\n",
    "                                                   s_RDEM['nested sampling global log-evidence error'] ))\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plot(thdata_UDEM, model_SEM([param0_SEM_init,param1_SEM_init, param2_SEM_init])(thdata_SEM), \\\n",
    "     '.', label='Initial SEM Model')\n",
    "plot(thdata_UDEM, \\\n",
    " model_RDEM([param0_RDEM_init,param1_RDEM_init, param2_RDEM_init, param3_RDEM_init, param4_RDEM_init])(thdata_RDEM), \\\n",
    " '--', label='Initial DEM Model')\n",
    "errorbar(xdata, ydata, yuncs, fmt='o', label='Data')\n",
    "plot(thdata_SEM, model_SEM(p_SEM.analyser.get_best_fit()['parameters'])(thdata_SEM), label='PMN SEM Model')\n",
    "plot(thdata_UDEM, model_UDEM(p_UDEM.analyser.get_best_fit()['parameters'])(thdata_UDEM), label='PMN UDEM Model')\n",
    "plot(thdata_RDEM, model_RDEM(p_RDEM.analyser.get_best_fit()['parameters'])(thdata_RDEM), label='PMN RDEM Model')\n",
    "legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(20,20))\n",
    "from numpy.polynomial import polynomial\n",
    "def time_polynomial(params):\n",
    "    # modelOut = np.zeros(tdata.size)\n",
    "    # for kc, coeff in enumerate(params):\n",
    "    #     modelOut += coeff * tdata**kc\n",
    "    if len(params):\n",
    "        return lambda tdata: polynomial.polyval(tdata, params)\n",
    "    else:\n",
    "        return lambda tdata: zeros(tdata.size)\n",
    "\n",
    "def orbital_polynomial(params):\n",
    "    # modelOut = np.zeros(xdata.size)\n",
    "    # for kc, coeff in enumerate(params):\n",
    "    #     modelOut += coeff * xdata**kc\n",
    "    # return modelOut\n",
    "    if len(params):\n",
    "        return lambda odata: polynomial.polyval(odata, params)\n",
    "    else:\n",
    "        return lambda odata: zeros(odata.size)\n",
    "\n",
    "def wavelength_polynomial(params):\n",
    "    # modelOut = np.zeros(ldata.size)\n",
    "    # for kc, coeff in enumerate(params):\n",
    "    #     modelOut += coeff * ldata**kc\n",
    "    # return modelOut\n",
    "    if len(params):\n",
    "        return lambda ldata: polynomial.polyval(ldata, params)\n",
    "    else:\n",
    "        return lambda ldata: zeros(ldata.size)\n",
    "\n",
    "def polynomial_model(params):\n",
    "    params_list= list(params.copy())[::-1]\n",
    "    timeParams  = array([params_list.pop() for _ in range(nTimeCoeffs)])\n",
    "    orbitParams = array([params_list.pop() for _ in range(nOrbitCoeffs)])\n",
    "    waveParams  = array([params_list.pop() for _ in range(nWaveCoeffs)])\n",
    "    return lambda tdata, odata, ldata: time_polynomial(timeParams)(tdata)      + \\\n",
    "                                       orbital_polynomial(orbitParams)(odata)  + \\\n",
    "                                       wavelength_polynomial(waveParams)(ldata)\n",
    "\n",
    "tdata, xdata, ldata = np.random.uniform(-10,10,(3,100))\n",
    "tdata.sort()\n",
    "xdata.sort()\n",
    "ldata.sort()\n",
    "\n",
    "# tdata, xdata, ldata = [np.linspace(-10,10,100) for _ in range(3)]\n",
    "for nTimeCoeffs in range(4):\n",
    "    for nOrbitCoeffs in range(4):\n",
    "        for nWaveCoeffs in range(4):\n",
    "            params = np.random.uniform(-20,20,nTimeCoeffs+nOrbitCoeffs+nWaveCoeffs)\n",
    "            plot(tdata, polynomial_model(params)(tdata,xdata,ldata),'.', alpha=0.5, mew=0)\n",
    "            plot(xdata, polynomial_model(params)(tdata,xdata,ldata),'.', alpha=0.5, mew=0)\n",
    "            plot(ldata, polynomial_model(params)(tdata,xdata,ldata),'.', alpha=0.5, mew=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nThPts= int(1e3)\n",
    "model_Poly  = polynomial_model\n",
    "\n",
    "xdata = h38_v1_orbitPhased['DeltaPhase']\n",
    "ydata = h38_v1_orbitPhased['Flux']\n",
    "yuncs = h38_v1_orbitPhased['Sigma']\n",
    "\n",
    "nTimeCoeffs     = 2\n",
    "nOrbitCoeffs    = 3\n",
    "nWaveCoeffs     = 0\n",
    "\n",
    "h38PlanetPhase  = h38_visit1['Phase']\n",
    "h38HSTPhase     = h38_v1_orbitPhased['DeltaPhase']\n",
    "\n",
    "xmin, xmax = xdata.min(), xdata.max()\n",
    "dx         = (xmax - xmin)/100\n",
    "thdata_Poly = np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "param0_Poly_init  = 1.0  # by defintion\n",
    "param1_Poly_init  = 1.0\n",
    "param2_Poly_init  = 1.0\n",
    "param3_Poly_init  = 1.0\n",
    "param4_Poly_init  = 1.0\n",
    "\n",
    "print(param0_Poly_init, param1_Poly_init, param2_Poly_init, param3_Poly_init, param4_Poly_init)\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plot(thdata_Poly, model_Poly([param0_Poly_init,param1_Poly_init,param2_Poly_init, param3_Poly_init, param4_Poly_init])(thdata_Poly))\n",
    "errorbar(xdata, ydata, yuncs, fmt='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "# model = sine_wave\n",
    "# parameters = [\"amp\", \"period\"]\n",
    "\n",
    "# model = straight_line\n",
    "# parameters = [\"offset\", \"slope\"]\n",
    "\n",
    "nTimeCoeffs     = 2\n",
    "nOrbitCoeffs    = 3\n",
    "nWaveCoeffs     = 0\n",
    "\n",
    "h38PlanetPhase  = h38_visit1['Phase']\n",
    "h38HSTPhase     = h38_v1_orbitPhased['DeltaPhase']\n",
    "\n",
    "model_Poly      = polynomial_model\n",
    "parameters_Poly = ['timeIntercept', 'timeSlope', 'orbitIntercept', 'orbitSlope', 'orbitQuadratic']\n",
    "\n",
    "cubeKWith = 1e3\n",
    "def myprior_Poly(cube, ndim, nparams):\n",
    "    for k in len(cube):\n",
    "        cube[k] = cube[k] * cubeKWith - 0.5*cubeKWith\n",
    "\n",
    "def myloglike_Poly(cube, ndim, nparams):\n",
    "    chi = 1.\n",
    "    # print \"cube\", [cube[i] for i in range(ndim)], cube\n",
    "    # for i in range(ndim):\n",
    "    #     chi *= -0.5 * ((cube[i] - 0.2) / 0.1)**2#math.cos(cube[i] / 2.) * math.sin(cube[i] / 2.)\n",
    "    # print \"returning\", math.pow(2. + chi, 5)\n",
    "    modelNow = model_Poly(cube)(times, HSTPhase, 0)\n",
    "    return -0.5*((modelNow - ydata)**2. / yuncs**2.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "# number of dimensions our problem has\n",
    "# parameters = [\"x\", \"y\"]\n",
    "n_params_Poly = len(parameters_Poly)\n",
    "\n",
    "savedir              = 'chains'\n",
    "planetName           = 'HAT38'\n",
    "visitName            = 'visit1'\n",
    "modelName            = 'polynomial_model'\n",
    "outputfiles_basename = savedir + '/' + planetName + '-' + visitName + '-' + modelName + '-'\n",
    "\n",
    "plt.figure(figsize=(5*n_params_Poly, 5*n_params_Poly))\n",
    "# we want to see some output while it is running\n",
    "progress = pymultinest.ProgressPlotter(n_params = n_params_Poly, outputfiles_basename=outputfiles_basename)\n",
    "\n",
    "progress.start()\n",
    "# threading.Timer(2, show, [\"chains/2-phys_live.points.pdf\"]).start() # delayed opening\n",
    "# run MultiNest\n",
    "pymultinest.run(myloglike_Poly, myprior_Poly, n_params_Poly, importance_nested_sampling = False, \\\n",
    "                resume = False, verbose = True, sampling_efficiency = 'model', n_live_points = 1000, \\\n",
    "                outputfiles_basename=outputfiles_basename)\n",
    "\n",
    "# ok, done. Stop our progress watcher\n",
    "progress.stop()\n",
    "\n",
    "# lets analyse the results\n",
    "a_Poly = pymultinest.Analyzer(n_params = n_params_Poly, outputfiles_basename=outputfiles_basename)\n",
    "s_Poly = a_Poly.get_stats()\n",
    "print('Polynomial took', time() - start, 'seconds')\n",
    "\n",
    "# fig = plt.gcf()\n",
    "# axs = fig.get_axes()\n",
    "\n",
    "# for ax in axs:\n",
    "#     ax.set_ylim()\n",
    "#     # ax.set_xscale(\"log\", nonposx='clip')\n",
    "#     # ax.set_yscale(\"log\", nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a_RDEM.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters_RDEM, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a_RDEM.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s_RDEM, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"Global Evidence:\\t%.15e +- %.15e\" % ( s_RDEM['nested sampling global log-evidence'], \\\n",
    "                                               s_RDEM['nested sampling global log-evidence error'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "\n",
    "# Here we will plot all the marginals and whatnot, just to show off\n",
    "# You may configure the format of the output here, or in matplotlibrc\n",
    "# All pymultinest does is filling in the data of the plot.\n",
    "\n",
    "# Copy and edit this file, and play with it.\n",
    "\n",
    "p_RDEM = pymultinest.PlotMarginalModes(a_RDEM)\n",
    "plt.figure(figsize=(5*n_params_RDEM, 5*n_params_RDEM))\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for i in range(n_params_RDEM):\n",
    "    plt.subplot(n_params_RDEM, n_params_RDEM, n_params_RDEM * i + i + 1)\n",
    "    p_RDEM.plot_marginal(i, with_ellipses = False, with_points = False, grid_points=50)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters_RDEM[i])\n",
    "    \n",
    "    for j in range(i):\n",
    "        plt.subplot(n_params_RDEM, n_params_RDEM, n_params_RDEM * j + i + 1)\n",
    "        #plt.subplots_adjust(left=0, bottom=0, right=0, top=0, wspace=0, hspace=0)\n",
    "        p_RDEM.plot_conditional(i, j, with_ellipses = False, with_points = False, grid_points=30)\n",
    "        plt.xlabel(parameters_RDEM[i])\n",
    "        plt.ylabel(parameters_RDEM[j])\n",
    "\n",
    "# plt.savefig(\"chains/marginals_multinest.pdf\") #, bbox_inches='tight')\n",
    "# show(\"chains/marginals_multinest.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "# plt.subplot2grid((5*n_params, 5*n_params), loc=(0,0))\n",
    "for i in range(n_params_RDEM):\n",
    "    # print(5*n_params, 1, i+1)\n",
    "    plt.subplot(5*n_params_RDEM, 1, i+1)\n",
    "    p_RDEM.plot_modes_marginal(i, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters_RDEM[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # outfile = '%s-mode-marginal-cumulative-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p_RDEM.plot_modes_marginal(i, cumulative = True, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.xlabel(parameters_RDEM[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_RDEM.analyser.get_best_fit()['parameters'], [param0_RDEM_init, param1_RDEM_init, param2_RDEM_init, param3_RDEM_init, param4_RDEM_init]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "plot(thdata_RDEM, model_RDEM([param0_RDEM_init,param1_RDEM_init, param2_RDEM_init, param3_RDEM_init, param4_RDEM_init])(thdata_RDEM), label='Initial Model')\n",
    "errorbar(xdata, ydata, yuncs, fmt='o', label='Data')\n",
    "plot(thdata_RDEM, model_RDEM(p_RDEM.analyser.get_best_fit()['parameters'])(thdata_RDEM), label='PMN Model')\n",
    "legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_RDEM.analyser.get_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
